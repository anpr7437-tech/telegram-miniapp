<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>MoveNet ‚Äî –¥–≤–∏–∂–µ–Ω–∏–µ —Ç–∞–∑–∞</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.14.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>

  <style>
    body {
      margin: 0;
      background: black;
      color: white;
      font-family: Arial, sans-serif;
      text-align: center;
    }

    video, canvas {
      width: 100%;
      max-height: 65vh;
      transform: scaleX(-1);
    }

    #value {
      font-size: 40px;
      margin: 10px 0;
    }

    #status {
      font-size: 18px;
      margin-bottom: 10px;
      opacity: 0.9;
    }

    button {
      width: 90%;
      padding: 16px;
      font-size: 18px;
      border-radius: 10px;
      border: none;
      background: #2ecc71;
      color: black;
      margin: 12px;
    }
  </style>
</head>
<body>

  <h2>üßç‚Äç‚ôÇÔ∏è –î–≤–∏–∂–µ–Ω–∏–µ —Ç–∞–∑–∞ (—Å–ø–µ—Ä–µ–¥–∏)</h2>

  <video id="video" playsinline muted></video>
  <canvas id="canvas"></canvas>

  <div id="value">–¢–∞–∑: --</div>
  <div id="status">–û–∂–∏–¥–∞–Ω–∏–µ</div>

  <button id="start">‚ñ∂ –í–∫–ª—é—á–∏—Ç—å –∫–∞–º–µ—Ä—É</button>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const valueEl = document.getElementById('value');
    const statusEl = document.getElementById('status');
    const startBtn = document.getElementById('start');

    let detector;

    async function initModel() {
      detector = await poseDetection.createDetector(
        poseDetection.SupportedModels.MoveNet,
        {
          modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING
        }
      );
      statusEl.innerText = '–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞';
    }

    async function loop() {
      const poses = await detector.estimatePoses(video);

      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      if (poses.length > 0) {
        const kp = poses[0].keypoints;

        const leftHip = kp.find(p => p.name === 'left_hip');
        const rightHip = kp.find(p => p.name === 'right_hip');

        if (leftHip && rightHip && leftHip.score > 0.4 && rightHip.score > 0.4) {
          const hipY = (leftHip.y + rightHip.y) / 2;
          valueEl.innerText = '–¢–∞–∑: ' + hipY.toFixed(0);

          ctx.fillStyle = 'red';
          [leftHip, rightHip].forEach(p => {
            ctx.beginPath();
            ctx.arc(p.x, p.y, 8, 0, Math.PI * 2);
            ctx.fill();
          });
        }
      }

      requestAnimationFrame(loop);
    }

    startBtn.onclick = async () => {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: 'user' }
      });

      video.srcObject = stream;
      await video.play();

      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      statusEl.innerText = '–°–ª–µ–∂—É –∑–∞ –¥–≤–∏–∂–µ–Ω–∏–µ–º —Ç–∞–∑–∞';
      await initModel();
      loop();
    };
  </script>

</body>
</html>
